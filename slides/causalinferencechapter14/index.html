<!DOCTYPE html>
<html lang="en-us">
<head>

  
  
  
  

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Wowchemy 5.7.0 for Hugo">

  
    <link rel="manifest" href="/manifest.webmanifest">
  

  <link rel="icon" type="image/png" href="/media/icon_hu9ccd2acdcd774e20fa34966445b706a8_6997380_32x32_fill_lanczos_center_3.png">
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hu9ccd2acdcd774e20fa34966445b706a8_6997380_192x192_fill_lanczos_center_3.png">

  <link rel="canonical" href="https://example.com/slides/causalinferencechapter14/">

  <title>Using the Propensity Score in Regressions for Causal Effects | Li Zhe</title>

  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/dist/reveal.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/dist/theme/black.min.css">

  
  
  
  
    
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css">
  

  
  
  
    
    
    <link rel="stylesheet" href="/css/reveal_custom.min.css">
  
</head>
<body>

  
<div class="reveal">
  <div class="slides">
    
    
    

    
    
    
    
    

    
    

    
    
    
      
<section data-noprocess data-shortcode-slide
  
      
      data-background-image="ZIBIN.jpg"
  >

<h1 id="using-the-propensity-score-in-regressions-for-causal-effects">Using the Propensity Score in Regressions for Causal Effects</h1>
<p>$$
\begin{aligned}
\
\end{aligned}
$$</p>
<center> Li Zhe <center>
<p>$$$$</p>
<center>School of Data Science, Fudan University <center> 
<p>$$$$</p>
<center>November 1, 2023<center>

    </section>
    

    
    
    
      

<section data-noprocess data-shortcode-slide
  
      
      data-background-image="body1.jpg"
  >

<h2 id="introduction">Introduction</h2>
<ul>
<li>
<p>This chapter discusses two simple methods to use the propensity score:</p>
<ul>
<li>the propensity score as a covariate in regressions</li>
<li>running regressions weighted by the inverse of the propensity score</li>
</ul>
</li>
<li>
<p><strong>Reasons</strong>:</p>
<ul>
<li>they are easy to implement, which involve only standard statistical software packages for regressions;</li>
<li>their properties are comparable to many more complex methods;</li>
<li>they can be easily extended to allow for flexible statistical models including machine learning algorithms.</li>
</ul>
</li>
</ul>

    </section>
    

    
    
    
      

<section data-noprocess data-shortcode-slide
  
      
      data-background-image="body1.jpg"
  >

<h3 id="outline">Outline</h3>
<ul>
<li>Regressions with the propensity score as a covariate
<ul>
<li><strong>Theorem 14.1</strong></li>
<li>Proposition 14.1</li>
</ul>
</li>
</ul>
<p>$$$$</p>
<ul>
<li>Regressions weighted by the inverse of the propensity score
<ul>
<li>Average causal effect
<ul>
<li>Theorem 14.2</li>
</ul>
</li>
<li>Average causal effect on the treated units
<ul>
<li>Table 14.1</li>
<li>Proposition 14.2</li>
<li>Theorem 14.3</li>
</ul>
</li>
</ul>
</li>
</ul>

    </section>
    

    
    
    
      

<section data-noprocess data-shortcode-slide
  
      
      data-background-image="body1.jpg"
  >

<h3 id="regressions-with-the-propensity-score-as-a-covariate">Regressions with the propensity score as a covariate</h3>
<p>$$
\text { Theorem 11.1 If } Z \perp\!\!\!\perp\{Y(1), Y(0)\} \mid X \text {, then } {\color{red}Z \perp\!\!\!\perp\{Y(1), Y(0)\} \mid e(X)} \text {. }
$$</p>
<ul>
<li>By Theorem 11.1, if unconfoundedness holds conditioning on $X$, then it also holds conditioning on $e(X)$: $\color{red}{Z \perp\!\!\!\perp\{Y(1), Y(0)\} \mid e(X) }.$</li>
<li>Analogous to (10.5), $\tau$ is also <mark>nonparametrically</mark> identified by
$$
\tau=E[E\{Y \mid Z=1, e(X)\}-E\{Y \mid Z=0, e(X)\}],
$$</li>
<li>$\Rightarrow$ The simplest regression specification is the OLS fit of $Y$ on $\{1, Z, e(X)\}$, with the coefficient of $Z$ as an estimator, denoted by $\tau_e$:
$$
\arg \min _{a, b, c} E\{Y-a-b Z-c e(X)\}^2
$$</li>
<li>$\tau_e$ defined as the coefficient of $Z$.</li>
<li>It is consistent for $\tau$ if
<ul>
<li>have a correct propensity score model</li>
<li>the outcome model is indeed linear in $Z$ and $e(X)$</li>
</ul>
</li>
<li>$\tau_e$ estimates $\tau_{\mathrm{O}}$ if we have a correct propensity score model even if the outcome model is <mark>completely misspecified</mark></li>
</ul>

    </section>
    

    
    
    
      

<section data-noprocess data-shortcode-slide
  
      
      data-background-image="body1.jpg"
  >

<h3 id="regressions-with-the-propensity-score-as-a-covariate-1">Regressions with the propensity score as a covariate</h3>
<p><mark>Theorem 14.1</mark> If $Z \perp\!\!\!\perp\{Y(1), Y(0)\} \mid X$, then the coefficient of $Z$ in the OLS fit of $Y$ on $\{1, Z, e(X)\}$ equals
$$
\tau_e=\tau_{\mathrm{O}}=\frac{E\left\{h_{\mathrm{O}}(X) \tau(X)\right\}}{E\left\{h_{\mathrm{O}}(X)\right\}},
$$
recalling that $h_{\mathrm{O}}(X)=e(X)\{1-e(X)\}$ and $\tau(X)=E\{Y(1)-Y(0) \mid X\}$.</p>
<p>$$
\begin{aligned}
\
\
\end{aligned}
$$</p>
<p><mark>Corollary 14.1</mark> If $Z \perp\!\!\!\perp\{Y(1), Y(0)\} \mid X$, then</p>
<ul>
<li>the coefficient of $Z-e(X)$ in the OLS fit of $Y$ on $Z-e(X)$ or $\{1, Z-e(X)\}$ equals $\tau_{\mathrm{O}}$;</li>
<li>the coefficient of $Z$ in the OLS fit of $Y$ on $\{1, Z, e(X), X\}$ equals $\tau_{\mathrm{O}}$.</li>
</ul>

    </section>
    

    
    
    
      

<section data-noprocess data-shortcode-slide
  
      
      data-background-image="body1.jpg"
  >

<h3 id="regressions-with-the-propensity-score-as-a-covariate-2">Regressions with the propensity score as a covariate</h3>
<ul>
<li>An unusual feature of Theorem 14.1 is that <strong>the overlap condition</strong> ($0 &lt; e(x) &lt; 1$) is not needed any more.</li>
<li>Even if some units have propensity score $e(X)$ equaling 0 or 1, their associate weight $e(X)\{1-e(X)\}$ is zero so that they do not contribute anything to the final parameter $\tau_O$.</li>
</ul>

    </section>
    

    
    
    
      

<section data-noprocess data-shortcode-slide
  
      
      data-background-image="body1.jpg"
  >

<h2 id="frischwaughlovell-theorem">Frisch–Waugh–Lovell Theorem</h2>
<p>The Frisch–Waugh–Lovell (FWL) theorem reduces multivariate OLS to univariate OLS and therefore facilitate the understanding and calculation of the OLS coefficients.</p>
<p><mark>Theorem A2.2 (sample FWL)</mark> With data $\left(Y, X_1, X_2, \ldots, X_p\right)$ containing column vectors, the coefficient of $X_1$ equals the coefficient of $\tilde{X}_1$ in the OLS fit of $Y$ or $\tilde{Y}$ on $\tilde{X}_1$, where</p>
<ul>
<li>$\tilde{Y}$ is the residual vector from the OLS fit of $Y$ on $\left(X_2, \ldots, X_p\right)$</li>
<li>$\tilde{X}_1$ is the residual from the OLS fit of $X_1$ on $\left(X_2, \ldots, X_p\right)$.</li>
</ul>
<p>$$$$</p>
<p>Based on the FWL theorem, we can obtain $\tau_e$ in two steps:</p>
<ul>
<li>first, we obtain the residual $\tilde{Z}$ from the OLS fit of $Z$ on ${1, e(X)}$;</li>
<li>then, we obtain $\tau_e$ from the OLS fit of $Y$ on $\tilde{Z}$.</li>
</ul>

    </section>
    

    
    
    
      

<section data-noprocess data-shortcode-slide
  
      
      data-background-image="body1.jpg"
  >

<h3 id="proof-of-theorem-141">Proof of Theorem 14.1</h3>
<p>The coefficient of $e(X)$ in the OLS fit of $Z$ on $\{1, e(X)\}$ is
$$
\begin{aligned}
\frac{\operatorname{cov}\{Z, e(X)\}}{\operatorname{var}\{e(X)\}} &amp; =\frac{E[\operatorname{cov}\{Z, e(X) \mid X\}]+\operatorname{cov}\{E(Z \mid X), e(X)\}}{\operatorname{var}\{e(X)\}} \\ &amp;=\frac{0+\operatorname{var}\{e(X)\}}{\operatorname{var}\{e(X)\}}=1,
\end{aligned}
$$</p>
<ul>
<li>the intercept is $E(Z)-E\{e(X)\}=0$</li>
<li>the residual is $\tilde{Z}=Z-e(X)$ (This makes sense since $Z-e(X)$ is uncorrelated with any function of $X$).</li>
</ul>
<p>Therefore, we can obtain $\tau_e$ from the univariate OLS fit of $Y$ on $Z-e(X)$ :
$$\small{\tau_e=\frac{\operatorname{cov}\{Z-e(X), Y\}}{\operatorname{var}\{Z-e(X)\}}}$$
The denominator simplifies to
$$
\begin{aligned}
\operatorname{var}\{Z-e(X)\} &amp; =E\{Z-e(X)\}^2 =e(X)+e(X)^2-2 e(X)^2=h_{\mathrm{O}}(X)
\end{aligned}
$$</p>

    </section>
    

    
    
    
      

<section data-noprocess data-shortcode-slide
  
      
      data-background-image="body1.jpg"
  >

<h3 id="proof-of-theorem-141-1">Proof of Theorem 14.1</h3>
<p>The numerator simplifies to
$$
\begin{aligned}
&amp; \operatorname{cov}\{Z-e(X), Y\} \\
= &amp; E[\{Z-e(X)\} Y] \\
= &amp; E[\{Z-e(X)\} Z Y(1)]+E[\{Z-e(X)\}(1-Z) Y(0)] \\
&amp; \quad \quad \quad{\color{red}(\text { since } Y=Z Y(1)+(1-Z) Y(0))} \\
= &amp; E[\{Z-Z e(X)\} Y(1)]-E[e(X)(1-Z) Y(0)] \\
= &amp; E[Z\{1-e(X)\} Y(1)]-E[e(X)(1-Z) Y(0)] \\
= &amp; E\left[e(X)\{1-e(X)\} \mu_1(X)\right]-E\left[e(X)\{1-e(X)\} \mu_0(X)\right] \\
&amp; \quad \quad \quad\text { {\color{red}(tower property and ignorability)} } \\
= &amp; E\left\{h_{\mathrm{O}}(X) \tau(X)\right\} .
\end{aligned}
$$</p>
<ul>
<li>From the proof of Theorem 14.1, we can simply run the OLS of $Y$ on the centered treatment $\tilde{Z} = Z - e(X)$.</li>
<li>Moreover, we can also include $X$ in the OLS fit which may improve efficiency in finite sample.</li>
</ul>

    </section>
    

    
    
    
      

<section data-noprocess data-shortcode-slide
  
      
      data-background-image="body1.jpg"
  >

<h3 id="comments-of-theorem-141-and-corollary-141">Comments of Theorem 14.1 and Corollary 14.1</h3>
<ul>
<li>Theorem 14.1 motivates a two-step estimator for $\tau_{\mathrm{O}}$:
<ul>
<li>first, fit a propensity score model to obtain $\hat{e}\left(X_i\right)$;</li>
<li>second, run OLS of $Y_i$ on $\left(1, X_i, \hat{e}\left(X_i\right)\right)$ to obtain the coefficient of $Z_i$.</li>
</ul>
</li>
<li>Corollary 14.1 motivates another two-step estimator for $\tau_{\mathrm{O}}$:
<ul>
<li>first, fit a propensity score model to obtain $\hat{e}\left(X_i\right)$;</li>
<li>second, run OLS of $Y_i$ on $Z_i-\hat{e}\left(X_i\right)$ to obtain the coefficient of $Z_i$.</li>
</ul>
</li>
</ul>
<p><strong>Remark</strong>: OLS is convenient for obtaining point estimators, the corresponding standard errors are incorrect due to <mark>the uncertainty in the first step estimation of the propensity score</mark>. We can use the bootstrap to approximate the standard errors.</p>

    </section>
    

    
    
    
      

<section data-noprocess data-shortcode-slide
  
      
      data-background-image="body1.jpg"
  >

<h4 id="regressions-weighted-by-the-inverse-of-the-propensity-score">Regressions weighted by the inverse of the propensity score</h4>
<p>We first re-examine the Hajek estimator of $\tau$ :
$$
\hat{\tau}^{\text {hajek }}=\frac{\sum_{i=1}^n \frac{Z_i Y_i}{\hat{e}\left(X_i\right)}}{\sum_{i=1}^n \frac{Z_i}{\hat{e}\left(X_i\right)}}-\frac{\sum_{i=1}^n \frac{\left(1-Z_i\right) Y_i}{1-\hat{e}\left(X_i\right)}}{\sum_{i=1}^n \frac{1-Z_i}{1-\hat{e}\left(X_i\right)}},
$$</p>
<ul>
<li>which equals the difference between the weighted means of the outcomes in the treatment and control groups.</li>
<li>Numerically, it is identical to the coefficient of $Z_i$ in the following weighted least squares (WLS) of $Y_i$ on $\left(1, Z_i\right)$.</li>
</ul>
<p><mark>Proposition 14.1</mark> $\hat{\tau}^{\text {hajek }}$ equals $\hat{\beta}$ from the following $WLS$ :</p>
<p>$$
(\hat{\alpha}, \hat{\beta})=\arg \min_{\alpha, \beta} \sum_{i=1}^n w_i\left(Y_i-\alpha-\beta Z_i\right)^2
$$</p>
<p>with weights
$$
w_i=\frac{Z_i}{\hat{e}\left(X_i\right)}+\frac{1-Z_i}{1-\hat{e}\left(X_i\right)}= \begin{cases}\frac{1}{\hat{e}\left(X_i\right)} &amp; \text { if } Z_i=1 \\ \frac{1}{1-\hat{e}\left(X_i\right)} &amp; \text { if } Z_i=0\end{cases}
$$</p>

    </section>
    

    
    
    
      

<section data-noprocess data-shortcode-slide
  
      
      data-background-image="body1.jpg"
  >

<h3 id="average-causal-effect">Average causal effect</h3>
<ul style="color: black">
<li>By Proposition 14.1, it is convenient to obtain $\hat{\tau}^{\text {hajek }}$ based on WLS.</li>
<li>However, due to the uncertainty in the estimated propensity score, the standard error <mark>reported by WLS is incorrect</mark> for the true standard error $\Rightarrow$ <strong>bootstrap</strong></li>
</ul>
<ul style="color: red">
<li>Why does the WLS give a consistent estimator for $\tau$ ?</li>
</ul>
<ul>
<li>Recall that in the CRE with a constant propensity score, we can simply use the coefficient of $Z_i$ in the OLS fit of $Y_i$ on $(1, Z_i)$ to estimate $\tau$.</li>
<li>In observational studies, units have different probabilities of receiving the treatment and control, respectively.</li>
<li>If we weight the treated units by $1 / e(X_i)$ and the control units by $1 /\{1-e(X_i)\}$, then they can represent the whole population and we effectively have <strong>a pseudo randomized experiment</strong>.</li>
<li>Consequently, the difference between the weighted means are consistent for $\tau$.</li>
<li>The numerical equivalence of $\hat{\tau}^{\text {hajek }}$ and WLS is not only a fun numerical fact itself but also useful for motivation more complex estimator with covariate adjustment.</li>
</ul>

    </section>
    

    
    
    
      

<section data-noprocess data-shortcode-slide
  
      
      data-background-image="body1.jpg"
  >

<h3 id="an-extension-to-a-more-complex-estimator">An extension to a more complex estimator</h3>
<ul>
<li>In the CRE, we can use the coefficient of $Z_i$ in the OLS fit of $Y_i$ on $(1, Z_i, X_i, Z_i X_i)$ to estimate $\tau$, where the covariates are centered with $\bar{X}=0$.</li>
<li>This is Lin (2013)&rsquo;s estimator which uses covariates to improve efficiency.</li>
<li>A natural extension to observational studies is to estimate $\tau$ using the coefficient of $Z_i$ in the WLS fit of $Y_i$ on $\left(1, Z_i, X_i, Z_i X_i\right)$ with weights defined in (14.1).</li>
<li>If the linear models
$$
E(Y \mid Z=1, X)=\beta_{10}+\beta_{1 x}^{\top} X, \quad E(Y \mid Z=0, X)=\beta_{00}+\beta_{0 x}^{\top} X,
$$
are correctly specified, then <mark>both OLS and WLS give consistent estimators for the coefficients</mark> and the estimators of the coefficient of $Z$ is consistent for $\tau$.</li>
<li>More interestingly, the estimator of the coefficient of $Z$ based on WLS is also consistent for $\tau$ if <strong>the propensity score model is correct and the outcome model is incorrect</strong>. $\Rightarrow$ the estimator based on WLS is <strong>doubly robust</strong>.</li>
</ul>

    </section>
    

    
    
    
      

<section data-noprocess data-shortcode-slide
  
      
      data-background-image="body1.jpg"
  >

<h3 id="a-doubly-robust-estimator">A doubly robust estimator</h3>
<ul>
<li>Let $\hat{e}(X_i)$ be the fitted propensity score and $(\mu_1(X_i, \hat{\beta}_1), \mu_0(X_i, \hat{\beta}_0))$ be the fitted values of the outcome means based on the WLS.</li>
<li>The outcome regression estimator is</li>
</ul>
<p>$$
\hat{\tau}_{\mathrm{wls}}^{\mathrm{reg}}= \frac{1}{n}\sum_{i=1}^n\mu_1\left(X_i, \hat{\beta}_1\right)-\frac{1}{n} \sum_{i=1}^n \mu_0\left(X_i, \hat{\beta}_0\right)
$$</p>
<ul>
<li>The doubly robust estimator for $\tau$ is</li>
</ul>
<p>$$
\hat{\tau}_{\mathrm{wls}}^{\mathrm{dr}}=\hat{\tau}_{\mathrm{wls}}^{\mathrm{reg}}+\frac{1}{n} \sum_{i=1}^n \frac{Z_i\left\{Y_i-\mu_1\left(X_i, \hat{\beta}_1\right)\right\}}{\hat{e}\left(X_i\right)}-\frac{1}{n} \sum_{i=1}^n \frac{\left(1-Z_i\right)\left\{Y_i-\mu_0\left(X_i, \hat{\beta}_0\right)\right\}}{1-\hat{e}\left(X_i\right)} .
$$</p>
<ul>
<li>An interesting result is that this doubly robust estimator equals the outcome regression estimator, which reduces to the coefficient of $Z_i$ in the WLS fit of $Y_i$ on $\left(1, Z_i, X_i, Z_i X_i\right)$ if we use weights (14.1).</li>
</ul>

    </section>
    

    
    
    
      

<section data-noprocess data-shortcode-slide
  
      
      data-background-image="body1.jpg"
  >

<h3 id="theorem-142">Theorem 14.2</h3>
<p style="color: blue">If $\bar{X}=0$ and $(\mu_1(X_i, \hat{\beta}_1), \mu_0(X_i, \hat{\beta}_0))=(\hat{\beta}_{10}+\hat{\beta}_{1 x}^{\top} X_i, \hat{\beta}_{00}+\hat{\beta}_{0 x}^{\top} X_i)$ based on the WLS fit of $Y_i$ on $\left(1, Z_i, X_i, Z_i X_i\right)$ with weights (14.1), then</p>
<p style="color: blue">$$
\hat{\tau}_{\mathrm{wls}}^{\mathrm{dr}}=\hat{\tau}_{\mathrm{wls}}^{\mathrm{reg}}=\hat{\beta}_{10}-\hat{\beta}_{00},
$$</p>
<p style="color: blue">which is the coefficient of $Z_i$ in the WLS fit.</p>
<p>$$$$</p>
<ul>
<li>Freedman and Berk (2008) showed that when the outcome model is correct, the WLS estimator is worse than the OLS estimator</li>
<li>When the errors have variance proportional to the inverse of the propensity scores, the WLS estimator will be more effcient than the OLS estimator.</li>
<li>The estimated standard error based on the WLS fit is not consistent for the true standard error because it <strong>ignores the uncertainty in the estimated propensity score</strong>.</li>
<li>This can be easily fixed by using the bootstrap to approximate the variance of the WLS estimator.</li>
<li>Nevertheless, they found that &ldquo;weighting may help under some circumstances&rdquo; because when the outcome model is incorrect, the
WLS estimator is still consistent if the propensity score model is correct.</li>
</ul>

    </section>
    

    
    
    
      

<section data-noprocess data-shortcode-slide
  
      
      data-background-image="body1.jpg"
  >

<h3 id="average-causal-effect-on-the-treated-units">Average causal effect on the treated units</h3>
<p><mark>Proposition 14.2</mark> $\hat{\tau}_{\mathrm{T}}^{\text {hajek }}$ is numerically identical to $\hat{\beta}$ in the following WLS:
$$
(\hat{\alpha}, \hat{\beta})=\arg \min_{\alpha, \beta} \sum_{i=1}^n w_{\mathrm{T} i}\left(Y_i-\alpha-\beta Z_i\right)^2
$$
with weights
$$
w_{\mathrm{T} i}=Z_i+\left(1-Z_i\right) \hat{o}\left(X_i\right)= \begin{cases}1 &amp; \text { if } Z_i=1 \\ \hat{o}\left(X_i\right) &amp; \text { if } Z_i=0\end{cases}
$$
where $\hat{o}\left(X_i\right)=\hat{e}\left(X_i\right) /\{1-\hat{e}\left(X_i\right)\}$</p>

    </section>
    

    
    
    
      

<section data-noprocess data-shortcode-slide
  
      
      data-background-image="body1.jpg"
  >

<h3 id="regression-estimators">Regression estimators</h3>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">CRE</th>
<th style="text-align:center">unconfounded observational studies</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">without $X$</td>
<td style="text-align:center">$Y_i \sim Z_i$</td>
<td style="text-align:center">$Y_i \sim Z_i$ with weights $w_i$</td>
</tr>
<tr>
<td style="text-align:center">with $X$</td>
<td style="text-align:center">$Y_i \sim\left(Z_i, X_i, Z_i X_i\right)$</td>
<td style="text-align:center">$Y_i \sim\left(Z_i, X_i, Z_i X_i\right)$ with weights $w_i$</td>
</tr>
</tbody>
</table>

    </section>
    

    
    
    
      

<section data-noprocess data-shortcode-slide
  
      
      data-background-image="body1.jpg"
  >

<h3 id="average-causal-effect-on-the-treated-units-1">Average causal effect on the treated units</h3>
<ul>
<li>If we center covariates with $\hat{X}(1)=0$, then we can estimate $\tau_{\mathrm{T}}$ using the coefficient of $Z_i$ in the WLS fit of $Y_i$ on $\left(1, Z_i, X_i, Z_i X_i\right)$ with weights defined in (14.2). Similarly, this estimator equals the regression estimator</li>
</ul>
<p>$$
\hat{\tau}_{\mathrm{T}, \mathrm{wls}}^{\mathrm{reg}}=\hat{\bar{Y}}(1)-\frac{1}{n_1} \sum_{i=1}^n Z_i \mu_0\left(X_i, \hat{\beta}_0\right)
$$</p>
<p>which also equals the doubly robust estimator</p>
<p>$$
\hat{\tau}_{\mathrm{T}, \mathrm{wls}}^{\mathrm{dr}}=\hat{\tau}_{\mathrm{T}, \mathrm{wls}}^{\mathrm{reg}}-\frac{1}{n_1} \sum_{i=1}^n \hat{o}\left(X_i\right)\left(1-Z_i\right)\left\{Y_i-\mu_0\left(X_i, \hat{\beta}_0\right)\right\}.
$$</p>
<p><mark>Theorem 14.3</mark> If $\hat{\bar{X}}(1)=0$ and $\mu_0(X_i, \hat{\beta}_0)=\hat{\beta}_{00}+\hat{\beta}_{0x}^{\top} X_i$ based on the WLS fit of $Y_i$ on $(1, Z_i, X_i, Z_i X_i)$ with weights (14.2), then</p>
<p>$$
\hat{\tau}_{\mathrm{T}, \mathrm{wls}}^{\mathrm{dr}}=\hat{\tau}_{\mathrm{T}, \mathrm{wls}}^{\mathrm{reg}}=\hat{\beta}_{10}-\hat{\beta}_{00},
$$</p>
<p>which is the coefficient of $Z_i$ in the $W L S$ fit.</p>

    </section>
    

    
    
  </div>
</div>



  
  <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/dist/reveal.min.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/plugin/markdown/markdown.min.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/plugin/notes/notes.min.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/plugin/search/search.min.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/plugin/math/math.min.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/plugin/zoom/zoom.min.js" crossorigin="anonymous"></script>

  
  
    <script src="https://cdn.jsdelivr.net/npm/reveal.js-menu@2.1.0/plugin.js" integrity="sha256-M6JwAjnRAWmi+sbXURR/yAhWZKYhAw7YXnnLvIxrdGs=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js-menu@2.1.0/menu.js" integrity="sha256-l14dklFcW5mWar6w/9KaW0fWVerf3mYr7Wt0+rXzFAA=" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js-menu@2.1.0/menu.css" integrity="sha256-0fU8HKLaTjgzfaV9CgSqbsN8ilA3zo6zK1M6rlgULd8=" crossorigin="anonymous">
  

  
  

  
  
  <script src="/js/wowchemy-slides.js"></script>

</body>
</html>
